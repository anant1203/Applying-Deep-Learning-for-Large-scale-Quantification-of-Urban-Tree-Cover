{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import imageio\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,Activation,Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "def normalization_image(image):\n",
    "    \"\"\"\n",
    "    This function reads a numpy array of \n",
    "    images and return the contents as a \n",
    "    numpy array.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        It has images as numpy array.\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    images: numpy array\n",
    "        Normalized the value of array\n",
    "        between 0 to 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    image= image.astype('float32')\n",
    "    image= image - np.mean(image)\n",
    "    image = image / np.std(image)\n",
    "    image = image[...,np.newaxis]\n",
    "    return image\n",
    "    \n",
    "def normalization_mask(mask):\n",
    "    \"\"\"\n",
    "    This function reads a numpy array of \n",
    "    mask and return the normalized contents\n",
    "    as a numpy array.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : numpy array\n",
    "        It has mask as numpy array.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mask: numpy array\n",
    "        Normalized the value of array\n",
    "        between 0 to 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    mask = mask/255\n",
    "    mask=mask[...,np.newaxis]\n",
    "    return mask\n",
    "\n",
    "\n",
    "def mask_preprocessing(mask_dir_path):\n",
    "    \"\"\"\n",
    "    This function reads a path of the\n",
    "    mask and return the gray scaled image \n",
    "    as a numpy array.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mask_dir_path : str\n",
    "        Read the mask directory.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    gray_img: numpy array\n",
    "        Return gray scale image as numpy array\n",
    "    \"\"\"\n",
    "    mask_files = [f for f in glob.glob(mask_dir_path + \"**/*color.png\", recursive=True)]\n",
    "    print(\"number of mask file :::\",len(mask_files))\n",
    "    mask_files.sort()\n",
    "    gray_img=[]\n",
    "    for i in mask_files:\n",
    "        mask_arr=imageio.imread(i)\n",
    "        gray_arr=cv2.cvtColor(mask_arr, cv2.COLOR_BGR2GRAY)\n",
    "        gray_img.append(gray_arr)\n",
    "        gray_img.append(resize(gray_arr,(224,224),preserve_range=True))\n",
    "    gray_img=np.array(gray_img)\n",
    "    return gray_img\n",
    "    \n",
    "def image_preprocessing(image_dir_path):\n",
    "    \"\"\"\n",
    "    This function reads a path of the\n",
    "    image and return the gray scaled \n",
    "    image as a numpy array.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_dir_path : str\n",
    "        Read the mask directory.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    image_array: numpy array\n",
    "        Return gray scale image as numpy array\n",
    "    \"\"\"\n",
    "    images_files = [f for f in glob.glob(image_dir_path + \"**/*.png\", recursive=True)]\n",
    "    print(\"number of mask file :::\",len(images_files))\n",
    "    images_files.sort()\n",
    "    image_array=[]\n",
    "    for i in images_files:\n",
    "        img=imageio.imread(i)\n",
    "        img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        image_array.append(resize(img,(224,224),preserve_range=True))\n",
    "    image_array=np.array(image_array)\n",
    "    return image_array\n",
    "\n",
    "def unet_model(output_channels):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function create the unet architecture\n",
    "    using mobile_net as a down sample layer\n",
    "    and transposed convultion layer as the upsample \n",
    "    layer.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    output_channels : integer\n",
    "        number of output channel in train mask\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        Return keras model object\n",
    "    \"\"\"\n",
    "\n",
    "  # This is the last layer of the model\n",
    "  last = keras.layers.Conv2DTranspose(\n",
    "      output_channels, 3, strides=2,\n",
    "      padding='same', activation='softmax')  #64x64 -> 128x128\n",
    "\n",
    "  inputs = keras.layers.Input(shape=[224, 224, 3])\n",
    "  x = inputs\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = down_stack(x)\n",
    "  x = skips[-1]\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    concat = keras.layers.Concatenate()\n",
    "    x = concat([x, skip])\n",
    "\n",
    "  x = last(x)\n",
    "\n",
    "  return keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    \"\"\"\n",
    "    This function create the upsampling \n",
    "    layer for the model using transposed\n",
    "    convolution\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filter : integer\n",
    "        Take value of filter used for upsampling\n",
    "    size : integer\n",
    "        take size of the mask\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    result : kearas layer\n",
    "        Return upsampling layer.\n",
    "    \"\"\"\n",
    "    \n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = keras.Sequential()\n",
    "  result.add(\n",
    "    keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "  result.add(keras.layers.BatchNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "      result.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "  result.add(keras.layers.ReLU())\n",
    "\n",
    "  return result\n",
    "\n",
    "def prediction(testing_image_arr):\n",
    "    \"\"\"\n",
    "    This function predit the mask of the test\n",
    "    image. Return the predicted mask array\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    testing_image_arr : numpy array\n",
    "        test image numpy array.\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    mask_pred : array\n",
    "        predicted mask arry.\n",
    "    \"\"\"\n",
    "    \n",
    "    mask_pred=[]\n",
    "    for image in testing_image_arr:\n",
    "        image=image[np.newaxis,...]\n",
    "        predicted = model.predict(image, verbose=1)\n",
    "        mask_pred.append(predicted)\n",
    "    return mask_pred\n",
    "        \n",
    "def calculating_iou(mask_real,temp_mask):\n",
    "    \"\"\"\n",
    "    This function calculate the intersection\n",
    "    over union.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mask_real : array\n",
    "        ground truth array.\n",
    "    temp_mask : array\n",
    "        predicted mask array.\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    mean_iou : decimal\n",
    "        mean intersection over union.\n",
    "    \"\"\"\n",
    "    arr_iou=[]\n",
    "    for i in range(len(mask_real)):\n",
    "        intersection = np.logical_and(mask_real[i],temp_mask[i])\n",
    "        union = np.logical_or(mask_real[i], temp_mask[i])\n",
    "        iou_score = np.sum(intersection) / np.sum(union)\n",
    "        arr_iou.append(iou_score)\n",
    "    arr_iou=np.array(arr_iou)\n",
    "    arr_iou= np.nan_to_num(arr_iou, copy=True, nan=1.0)\n",
    "    mean_iou=arr_iou.mean()\n",
    "    return mean_iou\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=('Trains the model and outputs predictions.'),\n",
    "        add_help='How to use', prog='model.py <args>')\n",
    "\n",
    "    # Required arguments path of dataset folder \"home/jupyter/dataset/\"\n",
    "    parser.add_argument(\"-d\", \"--data_path\", required=True,\n",
    "                        help=(\"Provide the path to the data folder\"))\n",
    "\n",
    "    args = vars(parser.parse_args())\n",
    "    \n",
    "    #passing the path of image and mask file to be trained and tested\n",
    "    mask_dir_path = read_file(args['data_path'] + '/mask/train/')\n",
    "    image_dir_path = read_file(args['data_path'] + '/image/train')\n",
    "    test_image_dir_path = read_file(args['data_path'] + '/image/val/')\n",
    "    ground_truth = read_file(args['data_path'] + '/mask/val/')\n",
    "    \n",
    "    #numpy array of the mask after normalization\n",
    "    train_mask=mask_preprocessing(mask_dir_path)\n",
    "    train_mask=loading_json(mask_dir_path,train_mask)\n",
    "    train_mask=normalization_mask(train_mask)\n",
    "    \n",
    "    #numpy array of the image after normalization\n",
    "    train_image=image_preprocessing(image_dir_path)\n",
    "    train_image=normalization_image(train_image)\n",
    "    \n",
    "    #numpy array of the test mask after normalization\n",
    "    test_mask=mask_preprocessing(ground_truth)\n",
    "    test_mask=loading_json(ground_truth,train_mask)\n",
    "    test_mask=normalization_mask(test_mask)\n",
    "    \n",
    "    #numpy array of the test image after normalization\n",
    "    test_image=image_preprocessing(test_image_dir_path)\n",
    "    test_image=normalization_image(test_image)\n",
    "    \n",
    "    \n",
    "    # setting up the model using mobile_net_v2\n",
    "    base_model = MobileNetV2(include_top=False)\n",
    "    # Use the activations of these layers\n",
    "    layer_names = [\n",
    "        'block_1_expand_relu',   # 64x64\n",
    "        'block_3_expand_relu',   # 32x32\n",
    "        'block_6_expand_relu',   # 16x16\n",
    "        'block_13_expand_relu',  # 8x8\n",
    "        'block_16_project',      # 4x4\n",
    "    ]\n",
    "    #removing the top layer of the mobile_net_v2\n",
    "    layers = [base_model.get_layer(name).output for name in layer_names]\n",
    "    #downsampling layer the semantic segementation model using Mobile_net_v2\n",
    "    down_stack = Model(inputs=base_model.input, outputs=layers)\n",
    "    # storing the upsample layer for concatenation\n",
    "    up_stack = [\n",
    "    upsample(512, 3),  # 4x4 -> 8x8\n",
    "    upsample(256, 3),  # 8x8 -> 16x16\n",
    "    upsample(128, 3),  # 16x16 -> 32x32\n",
    "    upsample(64, 3),   # 32x32 -> 64x64\n",
    "    ]\n",
    "    # calling model\n",
    "    model=unet_model(3)\n",
    "    # compiling the model.\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    # fitting the model\n",
    "    model.fit(train_image, train_mask, batch_size=1, epochs=5, verbose=1, shuffle=True)\n",
    "    # predicted mask\n",
    "    prediction_mask=prediction(test_image)\n",
    "    prediction_mask=np.array(prediction_mask)\n",
    "    #calculating intersection over union\n",
    "    mean_iou=calculating_iou(ground_truth,prediction_mask)\n",
    "    print(\"mean_iou:::\",mean_iou)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
